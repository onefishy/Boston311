\documentclass[twoside]{article}
\usepackage{aistats2016}
\usepackage{hyperref}
\usepackage{amsmath, amssymb, amsthm, graphicx, algorithm}
\usepackage{algpseudocode}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{blkarray}
\usepackage{xcolor}
\usepackage[all,cmtip]{xy}

% If your paper is accepted, change the options for the package
% aistats2016 as follows:
%
%\usepackage[accepted]{aistats2016}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

\newcommand{\A}{\mathcal{A}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\bN}{\mathbb{N}}
\newcommand{\bQ}{\mathbb{Q}}
\newcommand{\Exp}{\mathbb{E}}
\newcommand{\bC}{\mathbb{C}}
\newcommand{\bR}{\mathbb{R}}
\newcommand{\bZ}{\mathbb{Z}}
\newcommand{\bK}{\mathbb{K}}
\newcommand{\bF}{\mathbb{F}}

\newcommand{\fF}{\mathbf{F}}
\newcommand{\fA}{\mathbf{A}}
\newcommand{\Grp}{\mathbf{Grp}}
\newcommand{\Set}{\mathbf{Set}}
\newcommand{\Mor}{\mathrm{Mor}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\Gal}{\mathrm{Gal}}
\newcommand{\Char}{\mathrm{char}}
\newcommand{\SL}{\mathrm{SL}}
\newcommand{\GL}{\mathrm{GL}}
\newcommand{\Span}{\mathrm{span}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\Ext}{\mathrm{Ext}}
\newcommand{\im}{\mathrm{im}}
\newcommand{\col}{\mathrm{col}}
\newcommand{\argmax}{\mathrm{argmax}}
\newcommand{\cone}{\mathrm{cone}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\RP}{\mathbb{R}\mathrm{P}}
\newcommand{\tr}{\mathrm{tr}}

\newcommand{\df}{\overset{\text{def}}{=}}
%\newcommand{\deg}{\mathrm{deg}}

\newcommand{\vx}{\mathbf{x}}
\newcommand{\vy}{\mathbf{y}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\vd}{\mathbf{d}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vk}{\mathbf{k}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vS}{\mathbf{S}}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\bo}{\mathbf{1}}
\newcommand{\bz}{\mathbf{0}}
\newcommand{\id}{\mathrm{id}}

\theoremstyle{theorem}
\newtheorem{thm}{Theorem}

\theoremstyle{theorem}
\newtheorem{prop}{Proposition}
\theoremstyle{theorem}
\newtheorem{cor}{Corollary}

\theoremstyle{lemma}
\newtheorem{lemma}{Lemma}

\theoremstyle{definition}
\newtheorem{defn}{Definition}

\theoremstyle{example}
\newtheorem{ex}{Example}

\newcommand\undermat[2]{%
  \makebox[0pt][l]{$\smash{\underbrace{\phantom{%
    \begin{matrix}#2\end{matrix}}}_{\text{$#1$}}}$}#2}
    
\newcommand\overmat[2]{%
  \makebox[0pt][l]{$\smash{\color{black}\overbrace{\phantom{%
    \begin{matrix}#2\end{matrix}}}^{\text{\color{black}#1}}}$}#2}


\begin{document}
\input xy
\xyoption{all}
\xyoption{arc}
\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother
% If your paper is accepted and the title of your paper is very long,
% the style will print as headings an error message. Use the following
% command to supply a shorter title of your paper so that it can be
% used as headings.
%
%\runningtitle{I use this title instead because the last one was very long}

% If your paper is accepted and the number of authors is large, the
% style will print as headings an error message. Use the following
% command to supply a shorter version of the authors names so that
% they can be used as headings (for example, use only the surnames)
%
%\runningauthor{Surname 1, Surname 2, Surname 3, ...., Surname n}

\twocolumn[

\aistatstitle{Bayesian Models for Service Quality Analysis of the Boston City 311}

\aistatsauthor{ Jane Huang \And Isadora Nun \And Weiwei Pan \And Francisco Rivera}

\aistatsaddress{ Harvard University \And Harvard University \And Harvard University \And Harvard University} ]

\begin{abstract}
Fill in later.
\end{abstract}

\section{Introduction}

In 2015, Mayor Martin J. Walsh launched Boston 311, a platform to better enable residents of Boston to report non-emergency issues to the City, such as graffiti and broken street lights, and access City services. The program is similar to the 311 program that has been in place in New York City since 2003, and is aimed to streamline City services for Boston's residents. There is now a number of on-going and active data-analytics research projects based on the database of 311 service requests.

We suspect that analysis of response times will show complex patterns of heterogeneity. In particular, we are interested in the significance of the impact of  factors such as geography or neighborhood demographics. We will approach this in two ways:
\begin{enumerate}
\item We propose to model latent classes in respone time to service requests in the city of Boston. City officials describe service response time as roughlly depending on the type of request and the volume of requests.  
\item We will model the service response time as a function of the type as well as the location of the request.
\end{enumerate}

\section{Background}
\subsection{Bayesian Gaussian Mixture Models}
We will assume that our data is given by $Y = (\vy_1,\dots , \vy_N )$, where $\vy_n\in \bR^M$ is a vector encoding the reported location of the problem (in terms of longitude and latitude) and the request type. We will assume that $Y$ has a pdf that is a mixture of $K$ number of Gaussian components with parameters $\mu = \{\mu_k :  1\leq k\leq K\}$ and $\Sigma = \{\Sigma_k :  1\leq k\leq K\}$. Let $\pi \in \bR^k$ denote the set of mixture coefficients for this model. Then, the likelihood of observing $y_i$, given $\theta, \pi$ is
\begin{align}
L(\vy_n) = p(\vy_n | \mu, \Sigma, \pi) = \sum_{k=1}^K\pi_k \N(\vy_n | \mu_k, \Sigma_k )
\end{align}
where $\pi_k$ is the mixture coefficient for the $k$-th component. 

Alternatively, we can model the component membership information as missing data. That is, we model the component membership indicators as a set of latent variables, $Z = (\vz_1, \ldots, \vz_N)$, where $\vz_n \in \bR^K$ is a binary vector encoding of the membership of the $n$-th data in the $k$-th component. That is,
\begin{align}
\vz_{n, k} = \begin{cases}
1, & \vy_n\text{ belongs to the $k$-th component}\\
0, & \text{otherwise}
\end{cases}
\end{align}
We will assume that the probability of observing $\vz_n$, given the mixture coefficients, as
\begin{align}
p(\vz_n | \pi) = \prod_{k=1}^K \pi_k^{\vz_{n, k}}.
\end{align}
Now, we can rewrite the likelihood of our data set $Y$ as
\begin{align}
L(Y) = \prod_{n=1}^N\prod_{k=1}^K \N(y_n| \mu_k, \Sigma^{-1}_k)^{\vz_{nk}}.
\end{align}
Finally, a basic generative model for our mixture can be specified by the following:
\begin{align}
\pi &\sim Dir(\alpha_0)\\
\Sigma^{-1}_k &\sim Wish(W_0, \nu_0)\\
\mu_k | \Sigma^{-1}_k &\sim \N(\eta_0, (\beta_0 \Sigma^{-1}_k )^{-1})\\
z_n | \pi &\sim \prod_{k=1}^K \pi_k^{\vz_{n, k}}\\
y_n | Z, \mu, \Sigma^{-1} &\sim \prod_{k=1}^K \N(\mu_k, \Sigma^{-1}_k)^{\vz_{nk}}
\end{align}
Note that the parameters of our model is $\theta = (\alpha_0, W_0, \nu_0, \eta_0, \beta_0)$. 

\subsection{Hamiltonian Monte Carlo within Gibbs Sampling}

\subsection{Variational Inference}

\section{Bayesian GMM with Demographic Information as Covariates}
\bibliographystyle{abbrv}
\bibliography{GMMBib}

\end{document}


M = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [1, 1, 0, 0], [0, 0, 1, 1], [1, 1, 1, 1]])

intervals =
Dimension: 0
[0.0, 0.001): [41] + -[14]
[0.0, 0.001): -[19] + [11]
[0.0, 0.002): [8] + -[11]
[0.0, 0.002): [34] + -[14]
[0.0, 0.003): -[15] + [62]
[0.0, 0.005): [6] + -[0]
[0.0, 0.007): [31] + [29]
[0.0, 0.009000000000000001): [8] + [7]
[0.0, 0.014): -[7] + [0]
[0.0, infinity): [0]
Dimension: 1
[0.0, 0.001): [6,18] + [67,136] + [18,67] + [6,136]
[0.0, 0.005): [56,88] + [18,135] + -[56,135] + [18,88]
[0.0, 0.006): [72,78] + [45,78] + [10,45] + [10,18] + [18,135] + [55,72] + [55,135]
[0.002, 0.006): -[108,124] + [74,120] + [25,74] + [112,120] + [25,124] + [108,112]
[0.004, 0.007): [42,143] + [49,143] + [32,63] + [32,111] + [49,63] + [42,111]
[0.0, 0.007): [6,107] + [6,18] + [55,60] + [60,107] + [18,55]
[0.003, 0.007): [42,143] + [70,81] + [81,111] + [42,111] + [70,143]
[0.006, 0.008): [19,79] + [19,20] + [8,14] + [8,20] + [14,79]
[0.0, 0.008): [36,81] + [36,137] + [70,81] + [46,143] + -[32,111] + [32,46] + [70,143] + [111,137]
[0.0, 0.008): [40,98] + [40,116] + [116,124] + [25,124] + [25,98]
[0.005, 0.01): [41,43] + [41,65] + [19,79] + [79,140] + [65,140] + [19,43]
[0.0, 0.012): [6,136] + [6,18] + [23,130] + [60,118] + [18,55] + [118,123] + [123,130] + [23,136] + [55,60]
[0.009000000000000001, 0.016): [0,56] + [0,57] + [56,88] + [74,112] + [28,74] + [10,18] + [57,112] + [28,56] + [10,56] + [18,88]
[0.003, 0.017): [79,140] + [19,53] + [11,101] + [19,79] + [101,140] + [11,117] + [53,117]




M = np.array([[2, 1, 2, 1], [2, 3, 2, 3], [1, 1, 0, 0], [0, 0, 1, 1], [1, 1, 1, 1]])

intervals =
 
Dimension: 0
[0.0, 0.001): -[15] + [26]
[0.0, 0.002): -[13] + [17]
[0.0, 0.003): [28] + -[3]
[0.0, 0.003): [15] + -[5]
[0.0, 0.003): -[8] + [31]
[0.0, 0.003): -[25] + [3]
[0.0, 0.003): [24] + [15]
[0.0, 0.004): [18] + -[1]
[0.0, 0.004): [20] + [15]
[0.0, 0.004): [3] + [9]
[0.0, 0.005): [5] + -[1]
[0.0, 0.005): [14] + -[3]
[0.0, 0.005): -[4] + [3]
[0.0, 0.005): [5] + [11]
[0.0, 0.005): -[29] + [46]
[0.0, 0.006): -[12] + [3]
[0.0, 0.006): [2] + [3]
[0.0, 0.011): [29] + -[0]
[0.0, 0.012): [1] + [0]
[0.0, infinity): [2]
[0.0, infinity): [0]
Dimension: 1
[0.0, 0.006): -[27,53] + [27,43] + [34,43] + [34,53]
[0.006, 0.011): [20,73] + [34,53] + [26,45] + [5,15] + [32,73] + [43,45] + [15,26] + [22,24] + [5,32] + [34,43] + [20,22] + [24,53]
[0.008, 0.015): [1,51] + [36,51] + [5,20] + [20,36] + [1,5]
[0.006, 0.016): [26,45] + [11,68] + [19,61] + [24,68] + [15,26] + [27,43] + [11,19] + [43,45] + [15,61] + [24,27]
[0.011, 0.016): [9,56] + [31,50] + [39,50] + [31,56] + [9,39]
[0.006, 0.019): [3,33] + [12,21] + [38,39] + [28,38] + [8,21] + [39,50] + [12,16] + [28,33] + [16,40] + [8,31] + [31,50] + [3,40]





