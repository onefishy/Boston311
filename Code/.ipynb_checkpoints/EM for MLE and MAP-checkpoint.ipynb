{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM for MLE and MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Target Distribution\n",
    "Recall that in our model, we suppose that our data, $\\mathbf{X}=\\{\\mathbf{x}_1, \\ldots, \\mathbf{x}_K\\}$ is drawn from the mixture of $K$ number of Gaussian distributions. For each observation $\\mathbf{x}_n$ we have a latent variable $\\mathbf{z}_n$ that is a 1-of-$K$ binary vector with elements $z_{nk}$. We denote the set of latent variable by $\\mathbf{Z}$. Recall that the distibution of $\\mathbf{Z}$ given the mixing coefficients, $\\pi$, is given by\n",
    "\\begin{align}\n",
    "p(\\mathbf{Z} | \\pi) = \\prod_{n=1}^N \\prod_{k=1}^K \\pi_k^{z_{nk}} \n",
    "\\end{align}\n",
    "Recall also that the likelihood of the data is given by,\n",
    "\\begin{align}\n",
    "p(\\mathbf{X} | \\mathbf{Z}, \\mu, \\Sigma) =\\prod_{n=1}^N \\prod_{k=1}^K \\mathcal{N}\\left(\\mathbf{x}_n| \\mu_k, \\Sigma_k\\right)^{z_{nk}}\n",
    "\\end{align}\n",
    "Finally, in our basic model, we choose a Dirichlet prior for $\\pi$ \n",
    "\\begin{align}\n",
    "p(\\pi) = \\mathrm{Dir}(\\pi | \\alpha_0) = C(\\alpha_0) \\prod_{k=1}^K \\pi_k^{\\alpha_0 -1},\n",
    "\\end{align}\n",
    "where $C(\\alpha_0)$ is the normalizing constant for the Dirichlet distribution. We also choose a Normal-Inverse-Wishart prior for the mean and the covariance of the likelihood function\n",
    "\\begin{align}\n",
    "p(\\mu, \\Sigma) = p(\\mu | \\Sigma) p(\\Sigma) = \\prod_{k=1}^K \\mathcal{N}\\left(\\mu_k | \\mathbf{m}_0, \\mathbf{V}_0\\right) IW(\\Sigma_k|\\mathbf{S}_0, \\nu_0).\n",
    "\\end{align}\n",
    "Thus, the joint distribution of all the random variable is given by\n",
    "\\begin{align}\n",
    "p(\\mathbf{X}, \\mathbf{Z}, \\pi, \\mu, \\Sigma) = p(\\mathbf{X} | \\mathbf{Z}, \\mu, \\Sigma) p(\\mathbf{Z} | \\pi) p(\\pi) p(\\mu | \\Sigma) p(\\Sigma)\n",
    "\\end{align}\n",
    "\n",
    "### EM for MLE\n",
    "\n",
    "#### E-step:\n",
    "*Needs exposition*\n",
    "\\begin{align}\n",
    "r_{nk} = \\frac{\\pi_k p\\left(\\mathbf{x}_n | \\mu_k, \\Sigma_k\\right)}{\\sum_{k'=1}^K \\pi_{k'} p\\left(\\mathbf{x}_n | \\mu_{k'}, \\Sigma_{k'}\\right)}\n",
    "\\end{align}\n",
    "\n",
    "#### M-step:\n",
    "*Needs exposition*\n",
    "\\begin{align}\n",
    "\\pi_k &= \\frac{r_k}{N},\\;\\; r_k =\\sum_{n=1}^N r_{nk}\\\\\n",
    "\\mu_k &=\\frac{\\sum_{n=1}^N r_{nk}\\mathbf{x}_n}{r_k}\\\\\n",
    "\\Sigma_k &= \\frac{\\sum_{n=1}^N r_{nk} \\mathbf{x}_n\\mathbf{x}_n^\\top}{r_k} - \\mu_k\\mu_k^\\top\n",
    "\\end{align}\n",
    "\n",
    "### EM for MAP\n",
    "\n",
    "#### E-step:\n",
    "*Needs exposition*\n",
    "\\begin{align}\n",
    "r_{nk} = \\frac{\\pi_k p\\left(\\mathbf{x}_n | \\mu_k, \\Sigma_k\\right)}{\\sum_{k'=1}^K \\pi_{k'} p\\left(\\mathbf{x}_n | \\mu_{k'}, \\Sigma_{k'}\\right)}\n",
    "\\end{align}\n",
    "\n",
    "#### M-step:\n",
    "*Needs exposition*\n",
    "\\begin{align}\n",
    "\\pi_k &= \\frac{r_k + \\alpha_k - 1}{N + \\sum_{k=1}^K \\alpha_k - K},\\;\\; r_k =\\sum_{n=1}^N r_{nk}\\\\\n",
    "\\hat{\\mu}_k &=\\frac{r_k \\overline{\\mathbf{x}}_k + \\beta_0 \\mathrm{m}_0}{r_k + \\beta_0}\\\\\n",
    "\\overline{\\mathbf{x}}_k&= \\frac{\\sum_{n=1}^N r_{nk} \\mathbf{x}_n}{r_k}\\\\\n",
    "\\hat{\\Sigma}_k &= \\frac{\\mathbf{S}_0 + \\mathbf{S}_k + \\frac{\\beta_0r_k}{\\beta_0 + r_k}(\\overline{\\mathbf{x}}_k - \\mathbf{m}_0)(\\overline{\\mathbf{x}}_k - \\mathbf{m}_0)^\\top}{\\nu_0 + r_k + D + 2}\\\\\n",
    "\\mathbf{S}_k &= \\sum_{n=1}^N r_{nk} (\\mathbf{x}_n - \\overline{\\mathbf{x}}_k)(\\mathbf{x}_n - \\overline{\\mathbf{x}}_k)^\\top\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "import scipy.stats \n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "from sklearn import mixture\n",
    "from scipy.stats import multivariate_normal as MVN\n",
    "\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in data in 12.23 seconds.\n",
      "Filtered data in 0.63 seconds.\n",
      "Filtered data in 0.57 seconds.\n",
      "Dates processed in 293.93 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "requests = pd.read_csv('311__Service_Requests.csv')\n",
    "t2 = time.time()\n",
    "print \"Read in data in %.2f seconds.\" % (t2 - t1)\n",
    "\n",
    "t1 = time.time()\n",
    "closed_requests = requests[requests['CASE_STATUS'] == 'Closed']\n",
    "t2 = time.time()\n",
    "print \"Filtered data in %.2f seconds.\" % (t2 - t1)\n",
    "\n",
    "t1 = time.time()\n",
    "subset_requests = closed_requests[closed_requests['SUBJECT'] == 'Public Works Department']\n",
    "t2 = time.time()\n",
    "print \"Filtered data in %.2f seconds.\" % (t2 - t1)\n",
    "\n",
    "#t1 = time.time()\n",
    "#subset_requests = subset_requests[subset_requests['TYPE'] == 'Street Light Outages']\n",
    "#t2 = time.time()\n",
    "#print \"Filtered data in %.2f seconds.\" % (t2 - t1)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "for col in ['OPEN_DT', 'TARGET_DT', 'CLOSED_DT']:\n",
    "    subset_requests[col] = pd.to_datetime(subset_requests[col], infer_datetime_format=True)\n",
    "t2= time.time()\n",
    "print \"Dates processed in %.2f seconds.\" % (t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates filtered in 0.23 seconds.\n"
     ]
    }
   ],
   "source": [
    "begin = pd.to_datetime('March 15, 2014 12:00PM')\n",
    "end = pd.to_datetime('March 19, 2014 12:00PM')\n",
    "\n",
    "t1 = time.time()\n",
    "in_range = subset_requests[subset_requests['OPEN_DT'] > begin]\n",
    "in_range = in_range[in_range['OPEN_DT'] < end]\n",
    "t2= time.time()\n",
    "\n",
    "print \"Dates filtered in %.2f seconds.\" % (t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(943, 3)\n"
     ]
    }
   ],
   "source": [
    "print type(in_range['LATITUDE'].values)\n",
    "\n",
    "elapsed_time = in_range['CLOSED_DT'].values - in_range['OPEN_DT'].values\n",
    "elapsed_time = elapsed_time.astype('timedelta64[h]').astype('float64')\n",
    "\n",
    "data = np.hstack((elapsed_time.reshape((len(in_range), 1)), \n",
    "                  in_range['LATITUDE'].values.reshape((len(in_range), 1)), \n",
    "                  in_range['LONGITUDE'].values.reshape((len(in_range), 1))))\n",
    "print data.shape\n",
    "\n",
    "#-------------   data parameters\n",
    "N = data.shape[0] #number of observations\n",
    "K = 2 #number of components\n",
    "D = data.shape[1] #number of features per observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97136797  0.02863203]\n",
      "kmeans [[   59.46724891    42.31968745   -71.08698341]\n",
      " [ 7313.44444444    42.32208519   -71.09900741]]\n",
      "*******************\n",
      "mu [[   59.46724891    42.31968745   -71.08698341]\n",
      " [ 7313.44444444    42.32208519   -71.09900741]]\n",
      "Sigma0 [[ 1000.     0.     0.]\n",
      " [    0.  1000.     0.]\n",
      " [    0.     0.  1000.]]\n",
      "Sigma1 [[ 1000.     0.     0.]\n",
      " [    0.  1000.     0.]\n",
      " [    0.     0.  1000.]]\n"
     ]
    }
   ],
   "source": [
    "#we should initialize with k-means pi, mu, Sigma\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "########################################\n",
    "########################################\n",
    "#####         EM for MLE           #####\n",
    "########################################\n",
    "########################################\n",
    "\n",
    "def MLE_EM(K, D, N, X, pi_0, mu_0, Sigma_0, iters):\n",
    "    \n",
    "    r = np.zeros((N, K))\n",
    "    pi = pi_0\n",
    "    mu = mu_0\n",
    "    Sigma = Sigma_0\n",
    "    \n",
    "    #---------------- Likelihood ----------------#    \n",
    "    def lkhd(pi, mu, Sigma):\n",
    "        prob = np.zeros((N, K))\n",
    "        for k in xrange(K):\n",
    "            prob[:, k] = pi[k] * MVN.pdf(X, mu[k, :], Sigma[k])\n",
    "        return np.nan_to_num(prob)\n",
    "    \n",
    "    #---------------- E-Step ----------------#\n",
    "    def E_step():\n",
    "        prob = lkhd(pi, mu, Sigma) \n",
    "        return np.nan_to_num(np.diag(np.reciprocal(np.sum(prob, axis=1))).dot(prob))\n",
    "    \n",
    "    #---------------- M-Step ----------------#\n",
    "    def M_step():\n",
    "        r_ks = np.sum(r, axis=0)\n",
    "        print 'r_ks', r_ks\n",
    "        pi_new = 1. / N * r_ks\n",
    "        mu_new = np.nan_to_num(np.diag(np.reciprocal(r_ks)).dot(r.T.dot(X)))\n",
    "        \n",
    "        Sigma_new = []\n",
    "        for k in xrange(K):\n",
    "            Sigma_k = np.zeros((D, D))\n",
    "            for n in xrange(N):\n",
    "                Sigma_k += r[n, k] * np.outer(X[n, :] - mu[k, :], X[n, :] - mu[k, :])\n",
    "            Sigma_new.append(np.nan_to_num(Sigma_k / r_ks[k]))\n",
    "        print 'new Sig', Sigma_new[0]\n",
    "        print 'new Sig', Sigma_new[1]\n",
    "            \n",
    "        return pi_new, mu_new, Sigma_new\n",
    "    \n",
    "    #---------------- Alternate Between E and M-steps ----------------#\n",
    "    for i in xrange(iters):        \n",
    "        r = E_step()\n",
    "        pi, mu, Sigma = M_step()\n",
    "        \n",
    "    r = E_step()\n",
    "    \n",
    "    return pi, mu, Sigma, r\n",
    "\n",
    "########################################\n",
    "########################################\n",
    "#####         EM for MAP           #####\n",
    "########################################\n",
    "########################################\n",
    "\n",
    "def MAP_EM(K, D, N, X, pi_0, mu_0, Sigma_0, S_0, m_0, nu_0, beta_0, alpha_0, iters):\n",
    "    \n",
    "    #initialization of intermediate parameters\n",
    "    r = np.zeros((N, K))\n",
    "    pi = pi_0\n",
    "    mu = mu_0\n",
    "    Sigma = Sigma_0\n",
    "    S = [np.eye(D) for k in xrange(K)]\n",
    "    X_mean = mu_0\n",
    "    \n",
    "    #---------------- Likelihood ----------------#    \n",
    "    def lkhd(pi, mu, Sigma):\n",
    "        prob = np.zeros((N, K))\n",
    "        for k in xrange(K):\n",
    "            prob[:, k] = pi[k] * MVN.pdf(X, mu[k, :], Sigma[k])        \n",
    "        return prob\n",
    "    \n",
    "    #---------------- E-Step ----------------#\n",
    "    def E_step():\n",
    "        prob = lkhd(pi, mu, Sigma) \n",
    "        return np.diag(np.reciprocal(np.sum(prob, axis=1))).dot(prob)\n",
    "        \n",
    "    \n",
    "    #---------------- M-Step ----------------#\n",
    "    def M_step():\n",
    "        r_ks = np.sum(r, axis=0)\n",
    "        pi_new = (r_ks + alpha_0 - 1) * 1. / (N + np.sum(alpha_0) - K)\n",
    "        X_mean_new = np.nan_to_num(np.diag(np.reciprocal(r_ks)).dot(r.T.dot(X)))\n",
    "        mu_new = np.nan_to_num(np.diag(np.reciprocal(r_ks \n",
    "                                                     + beta_0)).dot(np.diag(r_ks).dot(X_mean) \n",
    "                                                                    + beta_0 * m_0))\n",
    "        S_new = []\n",
    "        Sigma_new = []\n",
    "        for k in xrange(K):            \n",
    "            c_1 = (beta_0 * r_ks[k]) / (beta_0 + r_ks[k])\n",
    "            c_2 = nu_0 + r_ks[k] + D + 2\n",
    "            Sigma_k = np.nan_to_num(S_0 + S[k] + c_1 \n",
    "                                    * np.outer(X_mean[k, :] - m_0, X_mean[k, :] - m_0))\n",
    "            Sigma_new.append(Sigma_k * 1./c_2)\n",
    "            \n",
    "            S_k = np.zeros((D, D))\n",
    "            for n in xrange(N):\n",
    "                S_k += r[n, k] * np.outer(X[n, :] - X_mean[k, :], X[n, :] - X_mean[k, :])\n",
    "                \n",
    "            S_new.append(S_k)\n",
    "        return pi_new, X_mean_new, mu_new, S_new, Sigma_new\n",
    "        \n",
    "    #---------------- Alternate Between E and M-steps ----------------#\n",
    "    for i in xrange(iters): \n",
    "        r = np.nan_to_num(E_step())\n",
    "        pi, X_mean, mu, S, Sigma = M_step()\n",
    "        \n",
    "    r = E_step()\n",
    "    \n",
    "    return pi, X_mean, mu, S, Sigma, r\n",
    "\n",
    "iters = 500\n",
    "\n",
    "#mu = np.array([[9, 9, 9], [1000, 1000, 1000]])\n",
    "Sigma = [1000. * np.eye(D), 1000. * np.eye(D)]\n",
    "#pi = np.array([0.5, 0.5])\n",
    "\n",
    "kmeans = KMeans(init='k-means++', n_clusters=K, n_init=1)\n",
    "kmeans.fit(data)\n",
    "mu = kmeans.cluster_centers_\n",
    "labels = kmeans.predict(data)\n",
    "cluster_0 = labels[labels == 0].shape[0]\n",
    "cluster_1 = labels[labels == 1].shape[0]\n",
    "pi = np.array([cluster_0 / (1. * cluster_0 + cluster_1), \n",
    "               cluster_1 / (1. * cluster_0 + cluster_1)])\n",
    "print pi\n",
    "print 'kmeans', mu\n",
    "print '*******************'\n",
    "#pi, mu, Sigma, r = MLE_EM(K, D, N, data, pi, mu, Sigma, iters)\n",
    "\n",
    "#print Sigma\n",
    "\n",
    "\n",
    "#random initialization of hyperparameters\n",
    "alpha_0 = np.random.random(K)\n",
    "beta_0 = np.random.random()\n",
    "m_0 = np.zeros(D)\n",
    "S_0 = np.eye(D)\n",
    "nu_0 = D + 1\n",
    "\n",
    "#pi, X_mean, mu, S, Sigma, r = MAP_EM(K, D, N, data, pi, mu, Sigma, S_0, m_0, nu_0, beta_0, alpha_0, iters)\n",
    "#print 'pi', pi\n",
    "print 'mu', mu\n",
    "print 'Sigma0', Sigma[0]\n",
    "print 'Sigma1', Sigma[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
